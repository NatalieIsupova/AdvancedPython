{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RiaParser(object):\n",
    "    def __init__(self, date=None, dateend=None):\n",
    "        \"\"\"\n",
    "        На вход ожидается строка вида '2018-10-15'\n",
    "        Или кортеж вида ('2018-10-14', '2018-10-15')\n",
    "        \"\"\"\n",
    "        if date is None:\n",
    "            self.date = self(datetime.now().date())\n",
    "        else:\n",
    "            if dateend is None:\n",
    "                self.date = date\n",
    "            else:\n",
    "                self.date = (date, dateend)\n",
    "        self.link = \"https://ria.ru/archive/\"\n",
    "        self.links = []\n",
    "\n",
    "    def _get_day_links(self, day):\n",
    "\n",
    "        # Я увидела, что с 1 раза не всегда открывается, поэтому решила дать ему 3 попытки\n",
    "        while True:\n",
    "            try:\n",
    "                # выкачиваем ссылки на новейшие статьи переданный день\n",
    "                resp = requests.get(self.link + day + '/')\n",
    "                # print('\\n', resp.status_code)\n",
    "                bss = BeautifulSoup(resp.text, \"html5lib\")\n",
    "                mega_link = bss.find(\"a\", class_=\"b-pager__button m-button-more\")[\n",
    "                    \"data-ajax\"]  # мегассыль на \"загрузить еще\"\n",
    "                date = re.search(r'\\d{8}', mega_link)[0]\n",
    "                break\n",
    "            except:\n",
    "                time.sleep(0.3) \n",
    "\n",
    "        # time = re.findall(r'\\d{6}', mega_link)[1]\n",
    "        # выкачивание ссылок на статьи\n",
    "        for element in bss.find_all(\"div\", class_=\"b-list__item\"):\n",
    "            link = element.find(\"a\")[\"href\"]\n",
    "            date = re.search(r'\\d{8}', link)[0]  # проверка нужной даты в ссылке\n",
    "            if date == day:\n",
    "                self.links.append(link)\n",
    "                print('Внимание! Обнаружено ', len(self.links), ' статей!\\r', end='')\n",
    "        # идем дальше в архив по нужному дню по ссылке, которую мы добыли\n",
    "        while date == day:\n",
    "            \n",
    "            # Я увидела, что с 1 раза не всегда открывается, поэтому решила дать ему 3 попытки\n",
    "            for i in range(3):\n",
    "                try:\n",
    "                    resp = requests.get('https://ria.ru/' + mega_link)\n",
    "                    # print('\\n', resp.status_code)\n",
    "                    bss = BeautifulSoup(resp.text, \"html5lib\")\n",
    "                    mega_link = bss.find(\"a\", class_=\"b-pager__button m-button-more\")[\"data-ajax\"]\n",
    "                    break\n",
    "                except:\n",
    "                    mega_link = None\n",
    "                    time.sleep(0.3)\n",
    "            # Если мы в конце концов ничего не скачали, то это означает, что ссылок больше нет\n",
    "            if mega_link is None:\n",
    "                break\n",
    "                \n",
    "            date = re.search(r'\\d{8}', mega_link)[0]\n",
    "            # выкачивание ссылок на статьи\n",
    "            for element in bss.find_all(\"div\", class_=\"b-list__item\"):\n",
    "                link = element.find(\"a\")[\"href\"]\n",
    "                date = re.search(r'\\d{8}', link)[0]  # проверка нужной даты в ссылке\n",
    "                if date == day:\n",
    "                    self.links.append(link)\n",
    "                    print('Внимание! Обнаружено ', len(self.links), ' статей!\\r', end='')\n",
    "        print()\n",
    "\n",
    "    def get_links(self):\n",
    "        if isinstance(self.date, str):\n",
    "            print('Обрабатываю ', self.date)\n",
    "            self._get_day_links(re.sub('-', '', self.date))\n",
    "        if isinstance(self.date, tuple):\n",
    "            day = datetime.strptime(self.date[0], '%Y-%m-%d').date()\n",
    "            delta = timedelta(days=1)\n",
    "            end = datetime.strptime(self.date[1], '%Y-%m-%d').date()\n",
    "            while day <= end:\n",
    "                print('Обрабатываю ', str(day))\n",
    "                self._get_day_links(re.sub('-', '', str(day)))\n",
    "                day += delta\n",
    "\n",
    "    def _get_article(self, link):\n",
    "        \"\"\"\n",
    "        Парсим название и тело статьи\n",
    "        \"\"\"\n",
    "        resp = requests.get(link)\n",
    "        bs = BeautifulSoup(resp.text, \"html5lib\")\n",
    "        try:\n",
    "            title = bs.h1.text.replace(\"\\xa0\", \" \")\n",
    "        except:\n",
    "            title = \"Без названия\"\n",
    "        class_name = \"b-article__body js-mediator-article mia-analytics\"\n",
    "        article = \"\"\n",
    "        article = \" \".join([para.text.replace(\"\\xa0\", \" \") for para in bs.find(\"div\", class_=class_name).find_all(\"p\")])\n",
    "        return title + \"\\n\" + article + \"\\n\"\n",
    "\n",
    "    def get_all_articles(self):\n",
    "        \"\"\"\n",
    "        Проходим по всем статьям и парсим их\n",
    "        \"\"\"\n",
    "        links = []  # список статей\n",
    "        self.allarticles = \"\"\n",
    "        count = 0  # это показатель, сколько статей обработано (т.к. все достаточно медленно)\n",
    "        success = 0\n",
    "        for link in self.links:\n",
    "            lk = \"https://ria.ru\" + link\n",
    "            # Не все статьи имеют такой вид, поэтому я тоже написала try, чтобы откинуть неправильные статьи\n",
    "            try:\n",
    "                self.allarticles += self._get_article(lk)\n",
    "                success += 1\n",
    "            except:\n",
    "                pass\n",
    "            count += 1\n",
    "            print('Обработано статей:', count, ' Успешно:', success, '\\r', end='')\n",
    "\n",
    "    \n",
    "    def to_txt(self, filename):\n",
    "        \"\"\"\n",
    "        Записываем в файл\n",
    "        \"\"\"\n",
    "        with open(filename, 'w', encoding='utf8') as f:\n",
    "            f.write(self.allarticles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "my = RiaParser('2018-08-31', '2018-09-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обрабатываю  2018-08-31\n",
      "Внимание! Обнаружено  380  статей!\n",
      "Обрабатываю  2018-09-01\n",
      "Внимание! Обнаружено  660  статей!\n",
      "Wall time: 19.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "my.get_links()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 5s 660  Успешно: 642 \n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "my.get_all_articles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8.01 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "my.to_txt('data.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
